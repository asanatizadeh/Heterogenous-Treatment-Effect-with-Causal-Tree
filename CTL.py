# -*- coding: utf-8 -*-
"""CTL.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15KAd_aPAXJTq6-FpKuZjTDwTDB-9UL40
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install causal_tree_learn

!pip install causalinference

!pip install pymatch

import pandas as pd
import matplotlib.pyplot as plt

from CTL.causal_tree_learn import CausalTree
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import scipy
import sklearn
import cython

#from causalinference import CausalModel
import seaborn as sns

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/ColabPractice/causal

ls

df = pd.read_csv('All_user_aggreagted.csv')

df.head()

df['count'].value_counts()

sns.kdeplot(df.loc[lambda df: df.treated == 0].rating, label= "untreated")
sns.kdeplot(df.loc[lambda df: df.treated == 1].rating, label= "treated")
plt.legend()

sns.kdeplot(df.loc[lambda df: df.treated == 0].sentiment, label= "untreated")
sns.kdeplot(df.loc[lambda df: df.treated == 1].sentiment, label= "treated")
plt.legend()

df['count']

sns.kdeplot(df.loc[lambda df: df.treated == 0]['count'], label= "untreated")
sns.kdeplot(df.loc[lambda df: df.treated == 1]['count'], label= "treated")
plt.legend()

df = df[[ "treated", "gender_c", "member_y", "rating", 'review_count']]
#review count shows user activity

df['Activity']= df['review_count']
df['Gender'] = df['gender_c']
df['Membership_years']= df['member_y']

df.columns

df.drop('review_count', inplace=True, axis=1)
df.drop('gender_c', inplace=True, axis=1)
df.drop('member_y', inplace=True, axis=1)

df.dropna(inplace=True)

df.describe()

df[df['treated']==1].sum()

df['rating'] = df['rating'].apply(lambda x: 1 if x>= 0 else -1)

df['rating'].value_counts()

y = df['rating'].values
treatment = df['treated'].values
x = df.drop(['rating', 'treated'], axis=1).values
columns = df.drop(['rating', 'treated'], axis=1).columns

#train test split
np.random.seed(0)
x_train, x_test, y_train, y_test, treat_train, treat_test = train_test_split(x, y, treatment,
                                                                             test_size=0.3, random_state=42)

# adaptive CT (Athey and Imbens, PNAS 2016)
ct_adaptive = CausalTree(weight=0.0, split_size=0.0)
ct_adaptive.fit(x_train, y_train, treat_train)
ct_adaptive.prune()
ct_adaptive_predict = ct_adaptive.predict(x_test)

ct_adaptive.plot_tree(features=columns, filename="output/bin_tree_adaptive", show_effect=True)

# honest CT (Athey and Imbens, PNAS 2016)
ct_honest = CausalTree(honest=True, weight=0.0, split_size=0.0)
ct_honest.fit(x_train, y_train, treat_train)
ct_honest.prune()
ct_honest_predict = ct_honest.predict(x_test)

ct_honest.plot_tree(features=columns, filename="output/causal_tree_honest", show_effect=True)

# honest CTL (CT-HL)
cthl = CausalTree(honest=True,)
cthl.fit(x_train, y_train, treat_train)
cthl.prune()
cthl_predict = cthl.predict(x_test)

cthl.plot_tree(features=columns, filename="output/bin=_tree_honest_learn", show_effect=True)

# regular CT-L
ctl = CausalTree(magnitude=False)
ctl.fit(x_train, y_train, treat_train)
ctl.prune()
ctl_predict = ctl.predict(x_test)

ctl.plot_tree(features=columns, filename="output/bin_tree", show_effect=True)
print(ctl_predict[:20])

# val honest CTL (CT-HV)
cthv = CausalTree(val_honest=True)
cthv.fit(x_train, y_train, treat_train)
cthv.prune()
cthv_predict = cthv.predict(x_test)

cthv.plot_tree(features=columns, filename="output/bin_tree_honest_validation", show_effect=True)

"""### Sentiment"""

df = pd.read_csv('All_user_aggreagted.csv')

df = df[[ "treated", "gender_c", "member_y", "sentiment", 'review_count']]

df['Activity']= df['review_count']
df['Gender'] = df['gender_c']
df['Membership_years']= df['member_y']

df.drop('review_count', inplace=True, axis=1)
df.drop('gender_c', inplace=True, axis=1)
df.drop('member_y', inplace=True, axis=1)

df.dropna(inplace=True)

df.describe()

df[df['treated']==1].sum()

df['sentiment'] = df['sentiment'].apply(lambda x: 1 if x>= 0 else -1)

df['sentiment'].value_counts()

y = df['sentiment'].values
treatment = df['treated'].values
x = df.drop(['sentiment', 'treated'], axis=1).values
columns = df.drop(['sentiment', 'treated'], axis=1).columns

#train test split
np.random.seed(0)
x_train, x_test, y_train, y_test, treat_train, treat_test = train_test_split(x, y, treatment,
                                                                             test_size=0.3, random_state=42)

# adaptive CT (Athey and Imbens, PNAS 2016)
ct_adaptive = CausalTree(weight=0.0, split_size=0.0)
ct_adaptive.fit(x_train, y_train, treat_train)
ct_adaptive.prune()
ct_adaptive_predict = ct_adaptive.predict(x_test)

ct_adaptive.plot_tree(features=columns, filename="output2/bin_tree_adaptive", show_effect=True)

# honest CT (Athey and Imbens, PNAS 2016)
ct_honest = CausalTree(honest=True, weight=0.0, split_size=0.0)
ct_honest.fit(x_train, y_train, treat_train)
ct_honest.prune()
ct_honest_predict = ct_honest.predict(x_test)

ct_honest.plot_tree(features=columns, filename="output2/causal_tree_honest", show_effect=True)

# regular CT-L
ctl = CausalTree(magnitude=False)
ctl.fit(x_train, y_train, treat_train)
ctl.prune()
ctl_predict = ctl.predict(x_test)

ctl.plot_tree(features=columns, filename="output2/bin_tree", show_effect=True)
print(ctl_predict[:20])

# honest CTL (CT-HL)
cthl = CausalTree(honest=True,)
cthl.fit(x_train, y_train, treat_train)
cthl.prune()
cthl_predict = cthl.predict(x_test)

cthl.plot_tree(features=columns, filename="output2/bin=_tree_honest_learn", show_effect=True)

# val honest CTL (CT-HV)
cthv = CausalTree(val_honest=True)
cthv.fit(x_train, y_train, treat_train)
cthv.prune()
cthv_predict = cthv.predict(x_test)

cthv.plot_tree(features=columns, filename="output2/bin_tree_honest_validation", show_effect=True)

"""### Review volume"""

df = pd.read_csv('All_user_aggreagted.csv')

df = df[[ "treated", "gender_c", "member_y", "count", 'review_count']]

df['Activity']= df['review_count']
df['Gender'] = df['gender_c']
df['Membership_years']= df['member_y']

df.drop('review_count', inplace=True, axis=1)
df.drop('gender_c', inplace=True, axis=1)
df.drop('member_y', inplace=True, axis=1)

df.dropna(inplace=True)

df.describe()

df[df['treated']==1].sum()

df['count'] = df['count'].apply(lambda x: 1 if x>= 0 else -1)

df['count'].value_counts()

y = df['count'].values
treatment = df['treated'].values
x = df.drop(['count', 'treated'], axis=1).values
columns = df.drop(['count', 'treated'], axis=1).columns

#train test split
np.random.seed(0)
x_train, x_test, y_train, y_test, treat_train, treat_test = train_test_split(x, y, treatment,
                                                                             test_size=0.3, random_state=42)

# adaptive CT (Athey and Imbens, PNAS 2016)
ct_adaptive = CausalTree(weight=0.0, split_size=0.0)
ct_adaptive.fit(x_train, y_train, treat_train)
ct_adaptive.prune()
ct_adaptive_predict = ct_adaptive.predict(x_test)

ct_adaptive.plot_tree(features=columns, filename="output3/bin_tree_adaptive", show_effect=True)

# honest CT (Athey and Imbens, PNAS 2016)
ct_honest = CausalTree(honest=True, weight=0.0, split_size=0.0)
ct_honest.fit(x_train, y_train, treat_train)
ct_honest.prune()
ct_honest_predict = ct_honest.predict(x_test)

ct_honest.plot_tree(features=columns, filename="output3/causal_tree_honest", show_effect=True)

# regular CT-L
ctl = CausalTree(magnitude=False)
ctl.fit(x_train, y_train, treat_train)
ctl.prune()
ctl_predict = ctl.predict(x_test)

ctl.plot_tree(features=columns, filename="output3/bin_tree", show_effect=True)
print(ctl_predict[:20])

# honest CTL (CT-HL)
cthl = CausalTree(honest=True,)
cthl.fit(x_train, y_train, treat_train)
cthl.prune()
cthl_predict = cthl.predict(x_test)

cthl.plot_tree(features=columns, filename="output3/bin=_tree_honest_learn", show_effect=True)

# val honest CTL (CT-HV)
cthv = CausalTree(val_honest=True)
cthv.fit(x_train, y_train, treat_train)
cthv.prune()
cthv_predict = cthv.predict(x_test)

cthv.plot_tree(features=columns, filename="output3/bin_tree_honest_validation", show_effect=True)